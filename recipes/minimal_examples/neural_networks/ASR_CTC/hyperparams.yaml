# Seed needs to be set at top of yaml, before objects with parameters are made
# NOTE: Seed does not guarantee replicability with CTC
seed: 1234
__set_seed: !apply:torch.manual_seed [!ref <seed>]

# Neural Parameters
N_epochs: 15
batch_size: 1
lr: 0.002
blank_index: 43

# Model parameters
activation: !name:torch.nn.LeakyReLU []
dropout: 0.15
cnn_blocks: 1
cnn_channels: (16,)
cnn_kernelsize: (3, 3)
rnn_layers: 1
rnn_neurons: 128
rnn_bidirectional: True
dnn_blocks: 1
dnn_neurons: 128

# Data:
data_folder: !PLACEHOLDER

train_examples: !apply:speechbrain.data_io.data_io.load_json
    json_path: !ref <data_folder>/train.json
    replacements:
        data_root: !ref <data_folder>
dev_examples: !apply:speechbrain.data_io.data_io.load_json
    json_path: !ref <data_folder>/dev.json
    replacements:
        data_root: !ref <data_folder>

label_encoder: !apply:speechbrain.data_io.encoders.CTCTextEncoder.fit_from_yaml
    data_collections: [!ref <train_examples>, !ref <dev_examples>]
    supervision: phn
    blank_encoding: !ref <blank_index>
    sup_transform: !name:speechbrain.utils.data_utils.split_by_whitespace

text_pipeline: !new:speechbrain.utils.data_utils.FuncPipeline
    - !name:speechbrain.utils.data_utils.split_by_whitespace
    - !ref <label_encoder.encode_sequence>
    - !name:speechbrain.data_io.data_io.to_longTensor

audio_pipeline: !new:speechbrain.utils.data_utils.FuncPipeline
    - !name:speechbrain.data_io.data_io.read_audio

data_tf:
    - !ref <text_pipeline>
    - !ref <audio_pipeline>

train_data: !apply:speechbrain.data_io.datasets.SegmentedDataset.from_extended_yaml
    examples: !ref <train_examples>
    data_transforms: !ref <data_tf>

valid_data: !apply:speechbrain.data_io.datasets.SegmentedDataset.from_extended_yaml
    examples: !ref <dev_examples>
    data_transforms: !ref <data_tf>

train_loader: !new:speechbrain.data_io.dataloader.SaveableDataLoader
    dataset: !ref <train_data>
    batch_size: !ref <batch_size>
    collate_fn: !name:speechbrain.data_io.batch.PaddedBatch

valid_loader: !new:speechbrain.data_io.dataloader.SaveableDataLoader
    dataset: !ref <valid_data>
    batch_size: !ref <batch_size>
    collate_fn: !name:speechbrain.data_io.batch.PaddedBatch

compute_features: !new:speechbrain.lobes.features.MFCC

mean_var_norm: !new:speechbrain.processing.features.InputNormalization
    norm_type: global

model: !new:speechbrain.lobes.models.CRDNN.CRDNN
    input_shape: [null, null, 660]
    activation: !ref <activation>
    dropout: !ref <dropout>
    cnn_blocks: !ref <cnn_blocks>
    cnn_channels: !ref <cnn_channels>
    cnn_kernelsize: !ref <cnn_kernelsize>
    time_pooling: True
    rnn_layers: !ref <rnn_layers>
    rnn_neurons: !ref <rnn_neurons>
    rnn_bidirectional: !ref <rnn_bidirectional>
    dnn_blocks: !ref <dnn_blocks>
    dnn_neurons: !ref <dnn_neurons>

lin: !new:speechbrain.nnet.linear.Linear
    input_size: !ref <dnn_neurons>
    n_neurons: 45  # 44 phonemes + 1 blank
    bias: False

softmax: !new:speechbrain.nnet.activations.Softmax
    apply_log: True

compute_cost: !name:speechbrain.nnet.losses.ctc_loss
    blank_index: !ref <blank_index>

modules:
    model: !ref <model>
    lin: !ref <lin>
    mean_var_norm: !ref <mean_var_norm>

opt_class: !name:torch.optim.Adam
    lr: !ref <lr>

per_stats: !name:speechbrain.utils.metric_stats.ErrorRateStats
