# Seed needs to be set at top of yaml, before objects with parameters are made
seed: 1234
__set_seed: !apply:torch.manual_seed [!ref <seed>]

# Neural Parameters
N_epochs: 15
batch_size: 2
lr: 0.002

# Data:
data_folder: !PLACEHOLDER

common_dynamic_items:
    alignments:
        func: !new:speechbrain.utils.data_utils.FuncPipeline
            - !name:speechbrain.data_io.data_io.load_pickle
            - !name:speechbrain.data_io.data_io.to_longTensor
        argkeys: [ali]
    sig:
        func: !name:speechbrain.data_io.data_io.read_audio
        argkeys: [wav]
common_output_keys: ["id", "sig", "alignments"]

train_data: !apply:speechbrain.data_io.dataset.DynamicItemDataset.from_json
    json_path: !ref <data_folder>/train.json
    replacements:
        data_root: !ref <data_folder>
    dynamic_items: !ref <common_dynamic_items>
    output_keys: !ref <common_output_keys>

valid_data: !apply:speechbrain.data_io.dataset.DynamicItemDataset.from_json
    json_path: !ref <data_folder>/dev.json
    replacements:
        data_root: !ref <data_folder>
    dynamic_items: !ref <common_dynamic_items>
    output_keys: !ref <common_output_keys>

compute_features: !new:speechbrain.lobes.features.MFCC

mean_var_norm: !new:speechbrain.processing.features.InputNormalization
    norm_type: global

# Model

linear1: !new:speechbrain.nnet.linear.Linear
    input_size: 660
    n_neurons: 1024
    bias: False

activation: !new:torch.nn.LeakyReLU

linear2: !new:speechbrain.nnet.linear.Linear
    input_size: 1024
    n_neurons: 43
    bias: False

softmax: !new:speechbrain.nnet.activations.Softmax
    apply_log: True

modules:
    linear1: !ref <linear1>
    linear2: !ref <linear2>
    mean_var_norm: !ref <mean_var_norm>

opt_class: !name:torch.optim.Adam
    lr: !ref <lr>

compute_cost: !name:speechbrain.nnet.losses.nll_loss

error_stats: !name:speechbrain.utils.metric_stats.MetricStats
    metric: !name:speechbrain.nnet.losses.classification_error
        reduction: batch
