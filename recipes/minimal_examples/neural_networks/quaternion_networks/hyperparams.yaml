# Seed needs to be set at top of yaml, before objects with parameters are made
# NOTE: Seed does not guarantee replicability with CTC
seed: 1234
__set_seed: !apply:torch.manual_seed [!ref <seed>]

# Data files
data_folder: !PLACEHOLDER
csv_train: !ref <data_folder>/train.csv
csv_valid: !ref <data_folder>/dev.csv
csv_test: !ref <data_folder>/test.csv

# Neural Parameters
N_epochs: 30
N_batch: 1
lr: 0.002

# Model parameters
activation: !new:torch.nn.Tanh

train_loader: !new:speechbrain.data_io.data_io.DataLoaderFactory
    csv_file: !ref <csv_train>
    batch_size: !ref <N_batch>
    csv_read: [wav, phn]
    sentence_sorting: ascending
    replacements:
        $data_folder: !ref <data_folder>

valid_loader: !new:speechbrain.data_io.data_io.DataLoaderFactory
    csv_file: !ref <csv_valid>
    batch_size: !ref <N_batch>
    csv_read: [wav, phn]
    sentence_sorting: ascending
    replacements:
        $data_folder: !ref <data_folder>

test_loader: !new:speechbrain.data_io.data_io.DataLoaderFactory
    csv_file: !ref <csv_test>
    csv_read: [wav, phn]
    sentence_sorting: ascending
    replacements:
        $data_folder: !ref <data_folder>

compute_features: !new:speechbrain.lobes.features.MFCC

mean_var_norm: !new:speechbrain.processing.features.InputNormalization
    norm_type: global

model: !new:speechbrain.nnet.containers.Sequential
    input_shape: [!ref <N_batch>, null, 660]  # input_size
    conv1: !name:speechbrain.nnet.quaternion_networks.quaternion_CNN.QuaternionConv1d  # yamllint disable-line rule:line-length
        out_channels: 32
        kernel_size: 3
    act1: !ref <activation>
    conv2: !name:speechbrain.nnet.quaternion_networks.quaternion_CNN.QuaternionConv1d  # yamllint disable-line rule:line-length
        out_channels: 64
        kernel_size: 3
    act2: !ref <activation>
    pooling: !new:speechbrain.nnet.pooling.Pooling1d
        pool_type: "avg"
        kernel_size: 3
    RNN: !name:speechbrain.nnet.quaternion_networks.quaternion_RNN.QuaternionLiGRU  # yamllint disable-line rule:line-length
        hidden_size: 64
        bidirectional: True

jit_module_keys: [model]

lin: !new:speechbrain.nnet.linear.Linear
    input_size: 512
    n_neurons: 43  # 42 phonemes + 1 blank
    bias: False

softmax: !new:speechbrain.nnet.activations.Softmax
    apply_log: True

modules:
    model: !ref <model>
    mean_var_norm: !ref <mean_var_norm>
    lin: !ref <lin>

opt_class: !name:torch.optim.Adam
    lr: !ref <lr>

compute_cost: !name:speechbrain.nnet.losses.ctc_loss
    blank_index: 42

per_stats: !name:speechbrain.utils.metric_stats.ErrorRateStats
