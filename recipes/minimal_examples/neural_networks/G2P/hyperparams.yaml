# Seed needs to be set at top of yaml, before objects with parameters are made
seed: 1234
__set_seed: !apply:torch.manual_seed [!ref <seed>]

# Data files
data_folder: !PLACEHOLDER

# Neural Parameters
N_epochs: 10
N_batch: 1
lr: 0.002

# Model parameters
activation: !name:torch.nn.LeakyReLU
rnn_layers: 1
rnn_neurons: 128
rnn_bidirectional: True

# token infomation
eos_bos_index: 1
blank_index: 0

char_encoder: !new:speechbrain.data_io.encoder.TextEncoder
label_encoder: !new:speechbrain.data_io.encoder.TextEncoder

common_dynamic_items:
    char_list:
        func: !name:speechbrain.utils.data_utils.split_by_whitespace
        argkeys: [char]
    char_encoded:
        func: !ref <char_encoder.encode_sequence_torch>
        argkeys: [char_list]
    phn_list:
        func: !name:speechbrain.utils.data_utils.split_by_whitespace
        argkeys: [phn]
    phn_encoded:
        func: !ref <label_encoder.encode_sequence>
        argkeys: [phn_list]
    phn_encoded_eos:
        func: !new:speechbrain.utils.data_utils.FuncPipeline
            - !ref <label_encoder.append_eos_index>
            - !name:speechbrain.data_io.data_io.to_longTensor
        argkeys: [phn_encoded]
    phn_encoded_bos:
        func: !new:speechbrain.utils.data_utils.FuncPipeline
            - !ref <label_encoder.prepend_bos_index>
            - !name:speechbrain.data_io.data_io.to_longTensor
        argkeys: [phn_encoded]
common_output_keys: ["id", "char_encoded", "phn_encoded_eos", "phn_encoded_bos"]

train_data: !apply:speechbrain.data_io.dataset.DynamicItemDataset.from_json
    json_path: !ref <data_folder>/train.json
    replacements:
        data_root: !ref <data_folder>
    dynamic_items: !ref <common_dynamic_items>
    output_keys: !ref <common_output_keys>

valid_data: !apply:speechbrain.data_io.dataset.DynamicItemDataset.from_json
    json_path: !ref <data_folder>/dev.json
    replacements:
        data_root: !ref <data_folder>
    dynamic_items: !ref <common_dynamic_items>
    output_keys: !ref <common_output_keys>

enc: !new:speechbrain.nnet.RNN.LSTM
    input_shape: [null, null, 128]
    bidirectional: True
    hidden_size: 64
    num_layers: 1
    dropout: 0.0

lin: !new:speechbrain.nnet.linear.Linear
    input_size: !ref <rnn_neurons>
    n_neurons: 44  # 43 phonemes + 1 eos
    bias: False

encoder_emb: !new:speechbrain.nnet.embedding.Embedding
    num_embeddings: 28  # 27 chars + 1 bos
    embedding_dim: 128

emb: !new:speechbrain.nnet.embedding.Embedding
    num_embeddings: 44  # 43 phonemes + 1 bos
    embedding_dim: 128

dec: !new:speechbrain.nnet.RNN.AttentionalRNNDecoder
    enc_dim: 128
    input_size: 128
    rnn_type: gru
    attn_type: content
    hidden_size: !ref <rnn_neurons>
    attn_dim: !ref <rnn_neurons>
    num_layers: 1

softmax: !new:speechbrain.nnet.activations.Softmax
    apply_log: True

modules:
    enc: !ref <enc>
    emb: !ref <emb>
    dec: !ref <dec>
    lin: !ref <lin>

opt_class: !name:torch.optim.Adam
    lr: !ref <lr>

searcher: !new:speechbrain.decoders.seq2seq.S2SRNNGreedySearcher
    embedding: !ref <emb>
    decoder: !ref <dec>
    linear: !ref <lin>
    bos_index: !ref <eos_bos_index>
    eos_index: !ref <eos_bos_index>
    blank_index: !ref <blank_index>
    min_decode_ratio: 0
    max_decode_ratio: 0.1

compute_cost: !name:speechbrain.nnet.losses.nll_loss

per_stats: !name:speechbrain.utils.metric_stats.ErrorRateStats
