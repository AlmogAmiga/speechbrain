# Basic parameters
data_folder: /Users/nauman/Desktop/Mila/nauman/data_folder/
sample_rate: 16000
seed: 1234
output_folder: !ref results/<seed>
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/train_log.txt

# Data (csv) files
csv_train: !ref <save_folder>/train.csv
csv_valid: !ref <save_folder>/dev.csv

# Xvector Data_prep Parameters
seg_dur: 300 # in msec
vad: False
splits: ["train", "dev"]

# Neural Parameters
number_of_epochs: 10
batch_size_: 6
lr: 0.002
device: 'cpu'

# Functions
compute_features: !new:speechbrain.lobes.features.fbank.Fbank
    n_mels: 24
    left_frames: 0
    right_frames: 0
    deltas: False

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <number_of_epochs>

model: !new:speechbrain.lobes.models.Xvector.Xvector
    tdnn_blocks: 1
    lin_blocks: 1

train_loader: !new:speechbrain.data_io.data_io.DataLoaderFactory
    &loader
    csv_file: !ref <csv_train>
    batch_size: !ref <batch_size_>
    csv_read: [wav, spk_id]
    sentence_sorting: original
    output_folder: !ref <output_folder>
    replacements:
        $data_folder: !ref <data_folder>

valid_loader: !new:speechbrain.data_io.data_io.DataLoaderFactory
    <<: *loader
    csv_file: !ref <csv_valid>

mean_var_norm: !new:speechbrain.processing.features.InputNormalization
    norm_type: global

linear: !new:speechbrain.nnet.linear.Linear
    n_neurons: 2
    bias: True

softmax: !new:speechbrain.nnet.activations.Softmax
    apply_log: True

compute_cost: !new:speechbrain.nnet.losses.ComputeCost
    cost_type: nll

compute_error: !new:speechbrain.nnet.losses.ComputeCost
    cost_type: error

optimizer: !new:speechbrain.nnet.optimizers.Optimize
    optimizer_type: adam
    learning_rate: !ref <lr>
