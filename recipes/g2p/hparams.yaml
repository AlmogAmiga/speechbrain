# Seed needs to be set at top of yaml, before objects with parameters are made
# NOTE: Seed does not guarantee replicability with CTC
seed: 1234
__set_seed: !!python/object/apply:torch.manual_seed [!ref <seed>]

# Data files
output_folder: /home/lugosch/data/mini-librispeech
data_folder: /home/lugosch/data/mini-librispeech

input_lexicon: !ref <data_folder>/lexicon.csv
output_lexicon: !ref <data_folder>/lexicon_augmented.csv

# These three files are created from lexicon.csv.
csv_train: !ref <data_folder>/train.csv
csv_valid: !ref <data_folder>/dev.csv
csv_test: !ref <data_folder>/test.csv

# Training hyperparameters
N_epochs: 2
N_batch: 1024
lr: 0.002

# token infomation
bos: 39
eos: 39

train_loader: !new:speechbrain.data_io.data_io.DataLoaderFactory
    csv_file: !ref <csv_train>
    batch_size: !ref <N_batch>
    csv_read: [graphemes,phonemes]
    sentence_sorting: random
    replacements:
        $data_folder: !ref <data_folder>

valid_loader: !new:speechbrain.data_io.data_io.DataLoaderFactory
    csv_file: !ref <csv_train>
    batch_size: !ref <N_batch>
    csv_read: [graphemes,phonemes]
    sentence_sorting: ascending
    replacements:
        $data_folder: !ref <data_folder>

test_loader: !new:speechbrain.data_io.data_io.DataLoaderFactory
    csv_file: !ref <csv_test>
    csv_read: [graphemes,phonemes]
    sentence_sorting: ascending
    replacements:
        $data_folder: !ref <data_folder>

encoder_embed: !new:speechbrain.nnet.embedding.Embedding
    num_embeddings: 27 # 27 graphemes
    embedding_dim: 256

encoder_net: !new:speechbrain.lobes.models.CRDNN.CRDNN
    activation: !name:torch.nn.LeakyReLU
    dropout: 0.15
    cnn_blocks: 0
    cnn_channels: 0
    cnn_kernelsize: 0
    time_pooling: False
    rnn_layers: 2
    rnn_neurons: 128
    rnn_bidirectional: True
    dnn_blocks: 0
    dnn_neurons: 0

decoder_embed: !new:speechbrain.nnet.embedding.Embedding
    num_embeddings: 40 # 39 phonemes + 1 bos
    embedding_dim: 256

decoder_net: !new:speechbrain.nnet.RNN.AttentionalRNNDecoder
    rnn_type: gru
    attn_type: content
    hidden_size: 256
    attn_dim: 256
    num_layers: 2

decoder_linear: !new:speechbrain.nnet.linear.Linear
    n_neurons: 40  # 39 phonemes + 1 eos
    bias: True

logsoftmax: !new:speechbrain.nnet.activations.Softmax
    apply_log: True

compute_cost: !name:speechbrain.nnet.losses.nll_loss

optimizer: !new:speechbrain.nnet.optimizers.Adam_Optimizer
    learning_rate: !ref <lr>
