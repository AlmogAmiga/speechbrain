# Tokenizer.
This folder contains the scripts to train a tokenizer using SentencePiece (https://github.com/google/sentencepiece


# How to run
python train.py train/1K_unigram_subword_bpe.yaml  
python train.py train/5K_unigram_subword_bpe.yaml
