# ############################################################################
# Tokenizer: subword BPE with unigram 1K
# Training: Librispeech 960h
# Authors:  Abdel Heba 2021
#           Mirco Ravanelli 2021
# ############################################################################


# Set up folders for reading from and writing to
data_folder: !PLACEHOLDER
output_folder: !ref ./results/tokenizer/
save_folder: !ref <output_folder>/save

# Manifets files are stored by default in the save folder.
train_annotation: !ref <save_folder>/train.json
valid_annotation: !ref <save_folder>/valid.json

# Tokenizer parameters
token_type: unigram  # ["unigram", "bpe", "char"]
token_output: 1000  # index(blank/eos/bos/unk) = 0
character_coverage: 1.0
csv_read: wrd # field to read

# Tokenizer object
tokenizer: !name:speechbrain.tokenizers.SentencePiece.SentencePiece
   model_dir: !ref <output_folder>
   vocab_size: !ref <token_output>
   csv_train: !ref <train_csv>
   csv_read: !ref <csv_read>
   model_type: !ref <token_type> # ["unigram", "bpe", "char"]
   character_coverage: !ref <character_coverage>
   csv_list_to_check: [!ref <train_csv>, !ref <valid_csv>]
